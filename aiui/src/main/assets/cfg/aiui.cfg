/* AIUI参数 */
{
    /*鉴权参数，请填写aiui官网的appid和key。*/
    "login":{
        "appid": "e4cddea8",
#         "appid": "7877036a",
        "key": "3574253046f936c3594c4baf7a8f5356"
#         "key": "075966bd9b33db50eeb6c986d8cacd2c"
    },

	/* interact_timeout：唤醒之后，一段时间内不说话则进入待唤醒状态，取值：[10000,180000)ms，默认为60000ms。仅continuous模式生效
	   result_timeout：检测说完一句话后（vad eos），一段时间内无云端结果则抛出10120错误码，默认5000ms。         */
	"interact":{
		"interact_timeout":"-1",
		"result_timeout":"5000"
	},

	/*scene：用户定制的场景参数，不同的场景可对应不同的云端处理流程。
	  clean_dialog_history：auto(自动清除历史,默认) user(开发者手动清除历史)*/
	"global":{
		"scene":"main_box",
# 		"scene":"main",
		"clean_dialog_history":"auto"
	},

    /*附加参数,用于绑定识别模型，设置翻译语种等
      设置合成下发url："tts_params":"tts_res_type=url"
      设置识别参数："iat_params":"{\"domain\":\"sms-aiui-ed\",\"svad\":\"1\"}"
                  domain：指定识别引擎，sms-aiui-ed(近场引擎)，tv(远场引擎)
                  svad：云端vad开关,1(开启),0(关闭)
    */
    "attachparams":{
         "iat_params":"{\"svad\":\"1\"}"
    },

	/* vad_enable：vad功能, 1（开启，默认）,0（关闭）
	engine_type:引擎类型，用户无需关注
	res_type:资源文件类型， path（通过res_path参数的路径加载资源文件），只有android支持assets
	res_path：资源路径的路径
	vad_bos:前端点等待时间，默认5000ms,超时会抛出vad timeout,自动结束对话(只对oneshot模式生效)
    vad_eos:后端点等待时间，默认1000ms，如果eos太小可能造成人的话还没说完，机器就结束对话了
    threshold：vad的阈值，取值范围0.1-0.9， 值越大越难触发vad
    speech_timeout:vad bos开始说话时计时，超过speech_timeout时间自动结束对话并回调vad eos，单位ms，默认60000ms，推荐5000ms(1s说4字，从统计结果看20字以上的对话没什么意义)
    */
	"vad":{
    	"vad_enable":"1",
    	"engine_type":"evad",
    	"res_type":"assets",
    	"res_path":"vad/evad_16k.jet",
    	"vad_bos":"5000",
    	"vad_eos":"1000",
    	"threshold":"0.7",
    	"speech_timeout":"5000"
    },

	// 识别（音频输入）参数
	"iat":{
		"sample_rate":"16000"
	},

	//动态实体配置
	"audioparams":{
	    "pers_param":"{\"appid\":\"\",\"uid\":\"\"}"
    },

	/*
	data_source: 音频数据来源，sdk（sdk主动录音）,user（开发者送音频byte[]到sdk）
	interact_mode: oneshot(一次唤醒，一次交互）,continuous(一次唤醒，持续交互，只支持安静场景，噪声环境下容易自言自语)
	intent_engine_type: cloud(云端识别，默认),local(离线识别),mixed(离线和云端同时识别，返回最快的结果),pipe(优先离线结果，无有效离线结果，再返回云端结果)
	*/
	"speech":{
	    "data_source":"user",
	    "interact_mode": "oneshot",
	    "intent_engine_type": "cloud"
	},

     /*离线识别配置,将intent_engine_type设置为local,mixed,pipe后生效
     engine_type：wfst(离线听写模式),wfst_fsa(离线听写+离线命令词),fsa(离线命令词)
     pgs_enable：回调离线识别中间结果，1(开启),0(关闭)
     res_type：资源类型，开发者不用关注
     res_path：离线识别资源路径
     preloads：离线语法文件(开发者编写的说法)
     */
     "esr":{
    	"engine_type": "fsa",
    	"pgs_enable": "1",
        "res_type":"assets",
    	"res_path":"esr/common.jet",
    	"preloads": [
    		{
    		    "id": 0,
    		    "res_type": "assets",
    		    "res_path": "esr/contact.jet"
    		}
    	]
    },

    /* tts参数
	ent: tts引擎版本
	engine_type:local(离线合成,依赖离线合成资源文件),cloud(在线合成),必须初始化时设置，不支持动态修改
	res_type:离线合成资源类型，assets表示从assets目录加载,engine_type=local时生效
	res_path:离线合成资源路径，engine_type=local时生效
	play_mode: sdk（sdk托管播放控制，只有此状态有AIUIConstant.EVENT_TTS回调） ，user（开发者在aiuiListener中event_result获取音频后，自己选择播放器播放）
	buffer_time:音频缓冲时长，当缓冲音频大于该值时才开始播放，默认值：1000ms
	stream_type:播放音频流类型，取值参考AudioManager类，默认值：3
	audio_focus:播放音频时是否抢占焦点，取值：1(抢占), 0（不抢占，默认值）
	*/
	"tts":{
        "ent": "xtts",
        "engine_type": "cloud",
        "res_type": "assets",
        "res_path": "xtts/xtts_common.jet;xtts/xtts_xiaoyan.jet",
        "play_mode":"sdk",
        "buffer_time": "0",
        "stream_type": "3",
        "audio_focus": "1"
    },

    //默认使用ws协议，下方配置使用wss协议
    "aiui_ssb":{
        "aiui_up_url":"wss://aiui-ipv6.openspeech.cn:443/aiui/v2.1/upload.do",
        "aiui_chid_url":"https://aiui-ipv6.openspeech.cn:443/v1.1/server/register"
    },

	/* 日志设置
	debug_log：开关日志,0(关闭) ,1(开启)
	save_datalog:保存音频开关,0(关闭) ,1(开启),默认保存路径：/sdcard/aiui/data
	*/
	"log":{
	    "debug_log":"0",
	    "save_datalog":"0",
	    "datalog_path":"",
	    "datalog_size":1024,
	    "raw_audio_path":""
	}
}